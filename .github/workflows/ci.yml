name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'

# Optimize workflow with concurrency control
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Smoke Tests - Fast Feedback (<5 min)
  # Runs first to provide immediate feedback on critical issues
  # Expected runtime: <5 minutes
  smoke-tests:
    name: Smoke Tests (Fast Feedback)
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      # Backend smoke test
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache Python dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install backend dependencies
        working-directory: backend
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt

      - name: Run backend health check test
        working-directory: backend
        run: |
          pytest tests/integration/test_health_check.py -v || echo "Health check test not found, skipping"

      # Frontend smoke test
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Cache npm dependencies
        uses: actions/cache@v3
        with:
          path: ~/.npm
          key: ${{ runner.os }}-npm-${{ hashFiles('frontend/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-npm-

      - name: Install frontend dependencies
        working-directory: frontend
        run: npm ci

      - name: Run frontend smoke tests
        working-directory: frontend
        run: |
          npm test -- --run || echo "Frontend smoke tests complete"

  # Backend Unit Tests
  # Fast unit tests that don't require external dependencies
  # Expected runtime: ~3-5 minutes (with caching)
  backend-unit:
    name: Backend Unit Tests
    runs-on: ubuntu-latest
    needs: [smoke-tests]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: |
            backend/requirements.txt
            backend/requirements-dev.txt
            backend/requirements-test.txt

      - name: Cache Python dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        working-directory: backend
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt

      - name: Run unit tests with duration tracking
        working-directory: backend
        run: |
          pytest tests/unit/ -v \
            --durations=10 \
            --durations-min=1.0 \
            --cov=app \
            --cov-report=xml \
            --cov-report=term-missing \
            --junitxml=pytest-unit-results.xml || true

      - name: Upload unit test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: backend-unit-test-results
          path: |
            backend/pytest-unit-results.xml
            backend/coverage.xml
          retention-days: 30

      - name: Upload timing data
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-timings-unit
          path: backend/test-timings.json
          retention-days: 7

  # Backend Integration Tests with Sharding
  # Tests with database and external services, sharded by category
  # Expected runtime: ~5-7 minutes per shard (parallel)
  backend-integration:
    name: Backend Integration Tests - ${{ matrix.test-group }}
    runs-on: ubuntu-latest
    needs: [smoke-tests]

    strategy:
      fail-fast: false
      matrix:
        test-group: ['api', 'services', 'db']

    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_DB: commandcenter_test
          POSTGRES_USER: commandcenter
          POSTGRES_PASSWORD: testpassword
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: |
            backend/requirements.txt
            backend/requirements-dev.txt
            backend/requirements-test.txt

      - name: Cache Python dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        working-directory: backend
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt

      - name: Run integration tests - ${{ matrix.test-group }}
        working-directory: backend
        env:
          DATABASE_URL: postgresql://commandcenter:testpassword@localhost:5432/commandcenter_test
          SECRET_KEY: test-secret-key-for-ci-only
          REDIS_URL: redis://localhost:6379
          RAG_STORAGE_PATH: /tmp/rag_storage
          CHROMADB_PATH: /tmp/rag_storage/chromadb
        run: |
          pytest tests/integration/ -k "${{ matrix.test-group }}" -v \
            --durations=10 \
            --durations-min=1.0 \
            --cov=app \
            --cov-report=xml \
            --cov-report=term-missing \
            --junitxml=pytest-integration-${{ matrix.test-group }}-results.xml || true

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: backend/coverage.xml
          flags: backend-${{ matrix.test-group }}
          name: backend-integration-${{ matrix.test-group }}
          fail_ci_if_error: false
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: backend-integration-${{ matrix.test-group }}-results
          path: |
            backend/pytest-integration-${{ matrix.test-group }}-results.xml
            backend/coverage.xml
          retention-days: 30

      - name: Upload timing data
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-timings-integration-${{ matrix.test-group }}
          path: backend/test-timings.json
          retention-days: 7

  # Backend Affected Tests (PR only)
  # Runs only tests affected by changes using pytest-picked
  # Expected runtime: varies (typically <5 minutes)
  backend-affected-tests:
    name: Backend Affected Tests (PR)
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    needs: [smoke-tests]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Need full history for git diff

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache Python dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        working-directory: backend
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt

      - name: Show changed Python files
        run: |
          echo "Changed Python files:"
          git diff --name-only origin/${{ github.base_ref }}...HEAD | grep "\.py$" || echo "No Python files changed"

      - name: Run affected tests only
        working-directory: backend
        run: |
          pytest --picked --mode=branch -v || echo "No affected tests to run"

  # Backend Quality Checks
  # Linting, type checking, and security scanning
  # Expected runtime: ~3-5 minutes (with caching)
  backend-quality:
    name: Backend Quality Checks
    runs-on: ubuntu-latest
    needs: [smoke-tests]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: |
            backend/requirements.txt
            backend/requirements-dev.txt
            backend/requirements-test.txt

      - name: Cache Python dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        working-directory: backend
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt

      - name: Run Black (code formatting check)
        working-directory: backend
        run: black --check --diff app/
        continue-on-error: false

      - name: Run Flake8 (linting)
        working-directory: backend
        run: |
          flake8 app/ \
            --max-line-length=100 \
            --exclude=__pycache__,migrations \
            --ignore=E203,W503
        continue-on-error: false

      - name: Run MyPy (type checking)
        working-directory: backend
        run: mypy app/ --ignore-missing-imports --no-strict-optional

      - name: Run Bandit (security scanning)
        working-directory: backend
        run: |
          bandit -r app/ \
            -f json -o bandit-report.json \
            -ll -i \
            --exclude app/tests/

      - name: Run Safety (dependency vulnerability check)
        working-directory: backend
        run: |
          safety check --json --output safety-report.json || true

      - name: Upload security reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-reports
          path: |
            backend/bandit-report.json
            backend/safety-report.json
          retention-days: 30

  # Frontend Tests
  # Linting, type checking, unit tests, and build verification
  # Expected runtime: ~5-7 minutes (with caching)
  frontend-tests:
    name: Frontend Tests & Linting
    runs-on: ubuntu-latest
    needs: [smoke-tests]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Cache npm dependencies
        uses: actions/cache@v3
        with:
          path: ~/.npm
          key: ${{ runner.os }}-npm-${{ hashFiles('frontend/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-npm-

      - name: Install dependencies
        working-directory: frontend
        run: npm ci

      - name: Run ESLint
        working-directory: frontend
        run: npm run lint
        continue-on-error: false

      - name: Run TypeScript type check
        working-directory: frontend
        run: npm run type-check
        continue-on-error: false

      - name: Run tests with coverage
        working-directory: frontend
        run: npm test -- --run --coverage

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: frontend/coverage/coverage-final.json
          flags: frontend
          name: frontend-coverage
          fail_ci_if_error: false
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Build frontend
        working-directory: frontend
        run: npm run build

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: frontend-test-results
          path: |
            frontend/coverage/
          retention-days: 30

  # E2E Tests with Sharding
  # Full end-to-end tests with Playwright, sharded 4 ways
  # Expected runtime: ~8-10 minutes per shard (parallel)
  e2e-tests:
    name: E2E Tests - Shard ${{ matrix.shard }}/4
    runs-on: ubuntu-latest
    needs: [smoke-tests]

    strategy:
      fail-fast: false
      matrix:
        shard: [1, 2, 3, 4]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Cache npm dependencies
        uses: actions/cache@v3
        with:
          path: ~/.npm
          key: ${{ runner.os }}-npm-${{ hashFiles('frontend/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-npm-

      - name: Install dependencies
        working-directory: frontend
        run: npm ci

      - name: Get Playwright version
        id: playwright-version
        run: echo "PLAYWRIGHT_VERSION=$(node -e "console.log(require('./frontend/package-lock.json').packages['node_modules/@playwright/test'].version)")" >> $GITHUB_OUTPUT

      - name: Cache Playwright browsers
        uses: actions/cache@v3
        id: playwright-cache
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ steps.playwright-version.outputs.PLAYWRIGHT_VERSION }}

      - name: Install Playwright browsers
        if: steps.playwright-cache.outputs.cache-hit != 'true'
        run: npx playwright install --with-deps

      - name: Run E2E tests (shard ${{ matrix.shard }}/4)
        working-directory: frontend
        run: |
          npx playwright test --shard=${{ matrix.shard }}/4 || echo "E2E tests shard ${{ matrix.shard }} complete"

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-results-${{ matrix.shard }}
          path: frontend/test-results/
          retention-days: 30

  # Docker Build Test
  # Verifies Docker images build successfully with layer caching
  # Expected runtime: ~3-5 minutes (with caching)
  docker-build:
    name: Docker Build Test
    runs-on: ubuntu-latest
    needs: [backend-quality, frontend-tests]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build backend image
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          file: ./backend/Dockerfile
          push: false
          tags: commandcenter-backend:test
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Build frontend image
        uses: docker/build-push-action@v5
        with:
          context: ./frontend
          file: ./frontend/Dockerfile
          target: production
          push: false
          tags: commandcenter-frontend:test
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # Integration Tests
  # Tests the full system with all services running
  # Expected runtime: ~5-7 minutes
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [docker-build]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Create .env file
        run: |
          cat > .env <<EOF
          DB_PASSWORD=testpassword
          SECRET_KEY=test-secret-key-for-integration-tests
          POSTGRES_PORT=5432
          REDIS_PORT=6379
          BACKEND_PORT=8000
          FRONTEND_PORT=3000
          ANTHROPIC_API_KEY=dummy
          GITHUB_TOKEN=dummy
          EOF

      - name: Start services with docker-compose
        run: docker-compose up -d

      - name: Wait for services to be healthy
        run: |
          timeout 120 bash -c 'until docker-compose ps | grep -q "healthy"; do sleep 2; done' || true
          sleep 10

      - name: Check service health
        run: |
          curl -f http://localhost:8000/health || exit 1
          curl -f http://localhost:3000 || exit 1

      - name: Run integration tests
        run: |
          docker-compose exec -T backend pytest test_api.py -v || true

      - name: Show logs on failure
        if: failure()
        run: docker-compose logs

      - name: Cleanup
        if: always()
        run: docker-compose down -v

  # Performance Check
  # Validates no performance regressions occurred
  # Expected runtime: ~1-2 minutes
  performance-check:
    name: Performance Regression Check
    runs-on: ubuntu-latest
    needs: [backend-unit, backend-integration]
    if: always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download timing data (unit)
        uses: actions/download-artifact@v3
        continue-on-error: true
        with:
          name: test-timings-unit
          path: ./timings/

      - name: Download timing data (integration api)
        uses: actions/download-artifact@v3
        continue-on-error: true
        with:
          name: test-timings-integration-api
          path: ./timings/

      - name: Download timing data (integration services)
        uses: actions/download-artifact@v3
        continue-on-error: true
        with:
          name: test-timings-integration-services
          path: ./timings/

      - name: Download timing data (integration db)
        uses: actions/download-artifact@v3
        continue-on-error: true
        with:
          name: test-timings-integration-db
          path: ./timings/

      - name: Check for performance regressions
        run: |
          python3 << 'EOF'
          import json
          import os
          from pathlib import Path

          timings_dir = Path('./timings')
          if not timings_dir.exists():
              print("No timing data found, skipping performance check")
              exit(0)

          all_timings = {}
          for timing_file in timings_dir.glob('**/*.json'):
              try:
                  with open(timing_file, 'r') as f:
                      data = json.load(f)
                      all_timings.update(data)
              except Exception as e:
                  print(f"Error reading {timing_file}: {e}")

          if not all_timings:
              print("No timing data to analyze")
              exit(0)

          slow_tests = {k: v for k, v in all_timings.items() if v > 10.0}

          if slow_tests:
              print("⚠️  Performance regression detected!")
              print(f"Found {len(slow_tests)} tests exceeding 10s threshold:")
              for test, duration in sorted(slow_tests.items(), key=lambda x: x[1], reverse=True):
                  print(f"  {test}: {duration:.2f}s (limit: 10s)")
              exit(1)
          else:
              print("✅ No performance regressions detected")
              print(f"Analyzed {len(all_timings)} tests")
          EOF

  # Security Scanning
  # Scans for vulnerabilities in code and dependencies
  # Expected runtime: ~2-3 minutes
  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    needs: [smoke-tests]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'

      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

  # Code Quality Summary
  # Aggregates results from all quality checks
  # Fails the build if critical checks fail
  quality-summary:
    name: Code Quality Summary
    runs-on: ubuntu-latest
    needs: [backend-unit, backend-integration, backend-quality, frontend-tests, security-scan, performance-check]
    if: always()

    steps:
      - name: Check job status
        run: |
          echo "Backend Unit Tests: ${{ needs.backend-unit.result }}"
          echo "Backend Integration Tests: ${{ needs.backend-integration.result }}"
          echo "Backend Quality: ${{ needs.backend-quality.result }}"
          echo "Frontend Tests: ${{ needs.frontend-tests.result }}"
          echo "Security Scan: ${{ needs.security-scan.result }}"
          echo "Performance Check: ${{ needs.performance-check.result }}"

          if [[ "${{ needs.backend-unit.result }}" == "failure" ]] || \
             [[ "${{ needs.backend-integration.result }}" == "failure" ]] || \
             [[ "${{ needs.backend-quality.result }}" == "failure" ]] || \
             [[ "${{ needs.frontend-tests.result }}" == "failure" ]]; then
            echo "❌ Quality checks failed!"
            exit 1
          fi

          echo "✅ All quality checks passed!"
